{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# English Text Analysis with Markov Chains\n",
    "\n",
    "This notebook visualizes the results of the Markov Chain analysis on *Alice's Adventures in Wonderland*.\n",
    "\n",
    "## Objectives\n",
    "1. Visualize Entropy Rate vs Model Order (k).\n",
    "2. Compare entropy of Character-level vs Word-level models.\n",
    "3. Compare Model Entropy with GZIP compression ratio.\n",
    "4. Analyze entropy variations across chapters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Set plot style\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (10, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metrics\n",
    "df = pd.read_csv('results/metrics.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Entropy Rate vs Model Order (Character Level)\n",
    "\n",
    "We expect the entropy rate to decrease as the order $k$ increases, reflecting the dependencies in English text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_df = df[df['level'] == 'char']\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(data=char_df, x='order', y='h_model', hue='keep_punct', marker='o', palette='viridis')\n",
    "plt.title('Character-level Entropy Rate vs Order')\n",
    "plt.xlabel('Order (k)')\n",
    "plt.ylabel('Entropy Rate (bits/char)')\n",
    "plt.xticks(char_df['order'].unique())\n",
    "plt.grid(True)\n",
    "plt.savefig('plots/char_entropy_vs_order.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Word Level Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_df = df[df['level'] == 'word']\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(data=word_df, x='order', y='h_model', hue='keep_punct', marker='o', palette='magma')\n",
    "plt.title('Word-level Entropy Rate vs Order')\n",
    "plt.xlabel('Order (k)')\n",
    "plt.ylabel('Entropy Rate (bits/word)')\n",
    "plt.xticks(word_df['order'].unique())\n",
    "plt.grid(True)\n",
    "plt.savefig('plots/word_entropy_vs_order.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Entropy vs GZIP Ratio\n",
    "\n",
    "We compare the estimated entropy rate (bits/symbol) with the compression ratio achieved by GZIP. Note that GZIP works on bytes, so the comparison is roughly against bits/character. For word models, the units differ significantly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for Character level, Punctuation=True for best comparison\n",
    "comp_df = df[(df['level'] == 'char') & (df['keep_punct'] == True)].copy()\n",
    "\n",
    "# GZIP ratio is compressed_size / original_size. \n",
    "# In bits per character, this is roughly ratio * 8 (assuming 1 byte per char input).\n",
    "comp_df['gzip_bits_per_char'] = comp_df['gzip_ratio'] * 8\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(comp_df['order'], comp_df['h_model'], marker='o', label='Markov Model Entropy (bits/char)')\n",
    "plt.axhline(y=comp_df['gzip_bits_per_char'].iloc[0], color='r', linestyle='--', label='GZIP Compression (bits/char)')\n",
    "\n",
    "plt.title('Entropy Rate vs GZIP Compression (Character Level)')\n",
    "plt.xlabel('Order (k)')\n",
    "plt.ylabel('Bits per Character')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('plots/entropy_vs_gzip.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Entropy by Chapter\n",
    "\n",
    "Analyzing how entropy varies across different chapters of the book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chap = pd.read_csv('results/chapter_entropy.csv')\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(data=df_chap, x='chapter', y='entropy', color='skyblue')\n",
    "plt.title('Entropy Rate per Chapter (Character Level, k=1)')\n",
    "plt.xlabel('Chapter')\n",
    "plt.ylabel('Entropy Rate (bits/char)')\n",
    "plt.ylim(3.0, 3.8) # Zoom in to see differences if small\n",
    "plt.savefig('plots/chapter_entropy.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Generated Text Samples\n",
    "\n",
    "Let's display some of the generated text samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results/generated_samples.txt', 'r') as f:\n",
    "    samples = f.read()\n",
    "\n",
    "# Print first 1000 chars\n",
    "print(samples[:2000])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
